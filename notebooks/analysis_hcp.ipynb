{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of the Human Connectome Project (funcional connectome)\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T20:04:15.431840Z",
     "start_time": "2021-08-03T20:04:14.753565Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "from mlconfound.stats import test_fully_confounded, test_partially_confounded\n",
    "from mlconfound.plot import plot_graph\n",
    "\n",
    "from mlxtend.evaluate import permutation_test\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "from statsmodels.formula.api import ols as ols_f\n",
    "from scipy.stats import kurtosis, skew\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, f_regression\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import quantile_transform\n",
    "\n",
    "from neurocombat_sklearn import CombatModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T12:43:07.129883Z",
     "start_time": "2021-08-01T12:42:54.233102Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data_in/hcp/subjectIDs.txt'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_112994/3894419447.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# HCP data can be obtainedc from the connectomeDB with special license\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;31m# data is not part of this repository\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0msubjectIDs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'../data_in/hcp/subjectIDs.txt'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mheader\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m netmats_pearson = pd.read_csv('../data_in/hcp/netmats1_correlationZ.txt',\n",
      "\u001B[0;32m~/src/mlconfound/venv/lib/python3.8/site-packages/pandas/util/_decorators.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    309\u001B[0m                     \u001B[0mstacklevel\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstacklevel\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    310\u001B[0m                 )\n\u001B[0;32m--> 311\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    312\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    313\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mwrapper\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/src/mlconfound/venv/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001B[0m in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001B[0m\n\u001B[1;32m    584\u001B[0m     \u001B[0mkwds\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkwds_defaults\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    585\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 586\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0m_read\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    587\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    588\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/src/mlconfound/venv/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001B[0m in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    480\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    481\u001B[0m     \u001B[0;31m# Create the parser.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 482\u001B[0;31m     \u001B[0mparser\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mTextFileReader\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    483\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    484\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mchunksize\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0miterator\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/src/mlconfound/venv/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[1;32m    809\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moptions\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"has_index_names\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mkwds\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"has_index_names\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    810\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 811\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_engine\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_make_engine\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mengine\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    812\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    813\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mclose\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/src/mlconfound/venv/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001B[0m in \u001B[0;36m_make_engine\u001B[0;34m(self, engine)\u001B[0m\n\u001B[1;32m   1038\u001B[0m             )\n\u001B[1;32m   1039\u001B[0m         \u001B[0;31m# error: Too many arguments for \"ParserBase\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1040\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mmapping\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mengine\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moptions\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# type: ignore[call-arg]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1041\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1042\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_failover_to_python\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/src/mlconfound/venv/lib/python3.8/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, src, **kwds)\u001B[0m\n\u001B[1;32m     49\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     50\u001B[0m         \u001B[0;31m# open handles\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 51\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_open_handles\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msrc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     52\u001B[0m         \u001B[0;32massert\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mhandles\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     53\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/src/mlconfound/venv/lib/python3.8/site-packages/pandas/io/parsers/base_parser.py\u001B[0m in \u001B[0;36m_open_handles\u001B[0;34m(self, src, kwds)\u001B[0m\n\u001B[1;32m    220\u001B[0m         \u001B[0mLet\u001B[0m \u001B[0mthe\u001B[0m \u001B[0mreaders\u001B[0m \u001B[0mopen\u001B[0m \u001B[0mIOHandles\u001B[0m \u001B[0mafter\u001B[0m \u001B[0mthey\u001B[0m \u001B[0mare\u001B[0m \u001B[0mdone\u001B[0m \u001B[0;32mwith\u001B[0m \u001B[0mtheir\u001B[0m \u001B[0mpotential\u001B[0m \u001B[0mraises\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    221\u001B[0m         \"\"\"\n\u001B[0;32m--> 222\u001B[0;31m         self.handles = get_handle(\n\u001B[0m\u001B[1;32m    223\u001B[0m             \u001B[0msrc\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    224\u001B[0m             \u001B[0;34m\"r\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/src/mlconfound/venv/lib/python3.8/site-packages/pandas/io/common.py\u001B[0m in \u001B[0;36mget_handle\u001B[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[1;32m    699\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mioargs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mencoding\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0;34m\"b\"\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mioargs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmode\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    700\u001B[0m             \u001B[0;31m# Encoding\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 701\u001B[0;31m             handle = open(\n\u001B[0m\u001B[1;32m    702\u001B[0m                 \u001B[0mhandle\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    703\u001B[0m                 \u001B[0mioargs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmode\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '../data_in/hcp/subjectIDs.txt'"
     ]
    }
   ],
   "source": [
    "# HCP data can be obtainedc from the connectomeDB with special license\n",
    "# data is not part of this repository\n",
    "subjectIDs = pd.read_csv('../data_in/hcp/subjectIDs.txt', header=None)\n",
    "\n",
    "netmats_pearson = pd.read_csv('../data_in/hcp/netmats1_correlationZ.txt',\n",
    "                             sep=' ',\n",
    "                             header=None)\n",
    "netmats_pearson['ID'] = subjectIDs[0]\n",
    "netmats_pearson.set_index('ID', drop=True, inplace=True)\n",
    "\n",
    "\n",
    "netmats_parcor = pd.read_csv('../data_in/hcp/netmats2_partial-correlation.txt',\n",
    "                             sep=' ',\n",
    "                             header=None)\n",
    "netmats_parcor['ID'] = subjectIDs[0]\n",
    "netmats_parcor.set_index('ID', drop=True, inplace=True)\n",
    "\n",
    "behavior = pd.read_csv('../data_in/hcp/hcp1200_behavioral_data.csv')\n",
    "behavior = behavior.set_index('Subject', drop=True)\n",
    "\n",
    "# convert age to numeric\n",
    "age = []\n",
    "for s in behavior['Age']:\n",
    "    if s == '36+':\n",
    "        age.append(36)\n",
    "    else:\n",
    "        split = s.split(sep='-')\n",
    "        age.append(np.mean((float(split[0]), float(split[1]))))\n",
    "\n",
    "behavior['age'] = age\n",
    "behavior\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-31T17:57:39.453512Z",
     "start_time": "2021-07-31T17:57:39.441003Z"
    }
   },
   "source": [
    "### Select target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T12:43:11.348485Z",
     "start_time": "2021-08-01T12:43:07.132838Z"
    }
   },
   "outputs": [],
   "source": [
    "##########################################################\n",
    "# change these\n",
    "target = 'PMAT24_A_CR' # fluid intelligence\n",
    "feature_data = netmats_parcor\n",
    "##########################################################\n",
    "\n",
    "sns.histplot(behavior[target], color='gray')\n",
    "plt.savefig('../data_out/fig/hcp_iq_nonnorm_hist.pdf')\n",
    "\n",
    "# it's a good practice to use pandas for merging, messing up subject order can be painful\n",
    "features = feature_data.columns\n",
    "df = behavior\n",
    "df = df.merge(feature_data, left_index=True, right_index=True, how='left')\n",
    "df = df.dropna(subset = [target] + features.values.tolist())\n",
    "y = df[target].values\n",
    "X = df[features].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-31T17:58:26.814045Z",
     "start_time": "2021-07-31T17:58:26.811341Z"
    }
   },
   "source": [
    "### Normalize target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T12:43:11.757399Z",
     "start_time": "2021-08-01T12:43:11.351829Z"
    }
   },
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(42)\n",
    "y_trf = quantile_transform(np.array([y+rng.uniform(0,1,len(y))-0.5]).T, output_distribution='normal', n_quantiles=1000).flatten()\n",
    "\n",
    "sns.histplot(y_trf, color='gray')\n",
    "plt.savefig('../data_out/fig/hcp_iq_quanttrf_hist.pdf')\n",
    "\n",
    "kurtosis(y_trf), skew(y_trf)\n",
    "y=y_trf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-31T17:58:55.155295Z",
     "start_time": "2021-07-31T17:58:55.151811Z"
    }
   },
   "source": [
    "# Machine Learning on raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T12:43:11.765603Z",
     "start_time": "2021-08-01T12:43:11.760627Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "    ('varthr', VarianceThreshold(0)),   # omit zero variance columns (diagonal)\n",
    "    #('fsel', SelectKBest(f_regression)),\n",
    "    ('model', Ridge(max_iter=100000))])\n",
    "\n",
    "p_grid = {#'fsel__k': [500, 1000, 2000],\n",
    "          'model__alpha': [0.000001, 0.01, 0.1, 1, 10, 100, 1000000]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T12:46:30.619416Z",
     "start_time": "2021-08-01T12:43:11.767453Z"
    }
   },
   "outputs": [],
   "source": [
    "# nested cv\n",
    "outer_cv = KFold(10)\n",
    "inner_cv = KFold(10)                                    \n",
    "clf = GridSearchCV(estimator=model, param_grid=p_grid, cv=inner_cv,\n",
    "                   scoring=\"neg_mean_squared_error\", verbose=True, return_train_score=False,\n",
    "                   n_jobs=-1)\n",
    "\n",
    "all_models = []\n",
    "best_params = []\n",
    "predicted = np.zeros(len(y))\n",
    "nested_scores_train = np.zeros(outer_cv.get_n_splits(X))\n",
    "nested_scores_test = np.zeros(outer_cv.get_n_splits(X))   \n",
    "                                    \n",
    "print(\"model\\tinner_cv mean score\\touter vc score\")\n",
    "i=0\n",
    "for train, test in outer_cv.split(X, y):\n",
    "\n",
    "    clf.fit(X[train], y[train])\n",
    "                                    \n",
    "    print('cv:', i, str(clf.best_params_) + \" \" + str(clf.best_score_) + \" \" + str(clf.score(X[test], y[test])))\n",
    "                                    \n",
    "    all_models.append(clf.best_estimator_)\n",
    "    best_params.append(clf.best_params_)\n",
    "    \n",
    "    predicted[test] = clf.predict(X[test])\n",
    "                                    \n",
    "    nested_scores_train[i] = clf.best_score_\n",
    "    nested_scores_test[i] = clf.score(X[test], y[test])\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-31T17:59:28.540617Z",
     "start_time": "2021-07-31T17:59:28.536907Z"
    }
   },
   "source": [
    "### Results (raw data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T12:46:35.118658Z",
     "start_time": "2021-08-01T12:46:30.628840Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"*** Score on mean as model:\\t\" + str(-mean_squared_error(np.repeat(y.mean(), len(y)), y)))\n",
    "print(\"** Mean score in the inner crossvaludation (inner_cv):\\t\" + str(nested_scores_train.mean()))\n",
    "print(\"** Mean Nested Crossvalidation Score (outer_cv):\\t\" + str(nested_scores_test.mean()))\n",
    "print(\"Explained Variance: \" +  str( 1- nested_scores_test.mean()/-mean_squared_error(np.repeat(y.mean(), len(y)), y) ))\n",
    "print(\"Correlation: \" + str(np.corrcoef(y, predicted)[0,1]))\n",
    "\n",
    "plt.figure(figsize=(5,2))\n",
    "sns.regplot(x=y, y=predicted, scatter=False, color='gray')\n",
    "sns.scatterplot(x=y, y=predicted, hue=df.age, palette=sns.color_palette(\"coolwarm\", as_cmap=True), alpha=0.4)\n",
    "plt.savefig('../data_out/fig/hcp_age_raw_regplot.pdf')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(5,2))\n",
    "sns.regplot(x=y, y=predicted, scatter=False, color='gray')\n",
    "sns.scatterplot(x=y, y=predicted, hue=df.Acquisition.astype(\"category\").cat.codes.values,\n",
    "                palette=sns.color_palette(\"coolwarm\", as_cmap=True), alpha=0.4)\n",
    "plt.savefig('../data_out/fig/hcp_acq_raw_regplot.pdf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-31T18:00:09.490554Z",
     "start_time": "2021-07-31T18:00:09.486785Z"
    }
   },
   "source": [
    "## Confound testing: age groups (raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T12:46:45.146084Z",
     "start_time": "2021-08-01T12:46:35.125796Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_graph(test_partially_confounded(y, predicted, df['age'],\n",
    "                                     random_state=42), outfile_base='../data_out/fig/hcp_age_raw_partial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T12:46:53.862711Z",
     "start_time": "2021-08-01T12:46:45.154913Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_graph(test_fully_confounded(y, predicted, df['age'],\n",
    "                                random_state=42), outfile_base='../data_out/fig/hcp_age_raw_full')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confound testing: acquisition batch (raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T12:47:10.084704Z",
     "start_time": "2021-08-01T12:46:53.868101Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_graph(test_partially_confounded(y, predicted, pd.Categorical(df['Acquisition'].values).codes, cat_c=True,\n",
    "                                     random_state=42), outfile_base='../data_out/fig/hcp_acq_raw_partial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T12:47:17.687890Z",
     "start_time": "2021-08-01T12:47:10.089889Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_graph(test_fully_confounded(y, predicted, pd.Categorical(df['Acquisition'].values).codes, cat_c=True,\n",
    "                                random_state=42), outfile_base='../data_out/fig/hcp_acq_raw_full')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regress out confounder from features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T12:47:45.869582Z",
     "start_time": "2021-08-01T12:47:17.692941Z"
    }
   },
   "outputs": [],
   "source": [
    "# regress-out age from connectivity\n",
    "X_adj = np.zeros_like(X)\n",
    "for i in range(X.shape[1]):\n",
    "    OLS_model = OLS(X[:,i], sm.add_constant(df.age)).fit()  # training the model\n",
    "    X_adj[:, i] = OLS_model.resid.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T12:50:33.907548Z",
     "start_time": "2021-08-01T12:47:46.089537Z"
    }
   },
   "outputs": [],
   "source": [
    "# nested cv\n",
    "outer_cv = KFold(10)\n",
    "inner_cv = KFold(10)                                    \n",
    "clf = GridSearchCV(estimator=model, param_grid=p_grid, cv=inner_cv,\n",
    "                   scoring=\"neg_mean_squared_error\", verbose=True, return_train_score=False,\n",
    "                   n_jobs=-1)\n",
    "\n",
    "all_models = []\n",
    "best_params = []\n",
    "predicted = np.zeros(len(y))\n",
    "nested_scores_train = np.zeros(outer_cv.get_n_splits(X_adj))\n",
    "nested_scores_test = np.zeros(outer_cv.get_n_splits(X_adj))   \n",
    "                                    \n",
    "print(\"model\\tinner_cv mean score\\touter vc score\")\n",
    "i=0\n",
    "for train, test in outer_cv.split(X_adj, y):\n",
    "\n",
    "    clf.fit(X_adj[train], y[train])\n",
    "                                    \n",
    "    print('cv:', i, str(clf.best_params_) + \" \" + str(clf.best_score_) + \" \" + str(clf.score(X_adj[test], y[test])))\n",
    "                                    \n",
    "    all_models.append(clf.best_estimator_)\n",
    "    best_params.append(clf.best_params_)\n",
    "    \n",
    "    predicted[test] = clf.predict(X_adj[test])\n",
    "                                    \n",
    "    nested_scores_train[i] = clf.best_score_\n",
    "    nested_scores_test[i] = clf.score(X_adj[test], y[test])\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results (feature regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T12:50:35.239315Z",
     "start_time": "2021-08-01T12:50:33.912296Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"*** Score on mean as model:\\t\" + str(-mean_squared_error(np.repeat(y.mean(), len(y)), y)))\n",
    "print(\"** Mean score in the inner crossvaludation (inner_cv):\\t\" + str(nested_scores_train.mean()))\n",
    "print(\"** Mean Nested Crossvalidation Score (outer_cv):\\t\" + str(nested_scores_test.mean()))\n",
    "print(\"Explained Variance: \" +  str( 1- nested_scores_test.mean()/-mean_squared_error(np.repeat(y.mean(), len(y)), y) ))\n",
    "print(\"Correlation: \" + str(np.corrcoef(y, predicted)[0,1]))\n",
    "\n",
    "plt.figure(figsize=(5,2))\n",
    "sns.regplot(x=y, y=predicted, scatter=False, color='gray')\n",
    "sns.scatterplot(x=y, y=predicted, hue=df.age, palette=sns.color_palette(\"coolwarm\", as_cmap=True), alpha=0.4)\n",
    "plt.savefig('../data_out/fig/hcp_age_reg_regplot.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confound test (feature regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T12:50:41.963426Z",
     "start_time": "2021-08-01T12:50:35.243799Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_graph(test_partially_confounded(y, predicted, df['age'], random_state=42),\n",
    "          outfile_base='../data_out/fig/hcp_age_reg_partial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T12:50:48.180928Z",
     "start_time": "2021-08-01T12:50:41.966080Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_graph(test_fully_confounded(y, predicted, df['age'], random_state=42),\n",
    "           outfile_base='../data_out/fig/hcp_age_reg_full')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regress out acquisition batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T12:52:49.853562Z",
     "start_time": "2021-08-01T12:50:48.184011Z"
    }
   },
   "outputs": [],
   "source": [
    "# regress-out acquisition from connectivity\n",
    "X_adj = np.zeros_like(X)\n",
    "for i in range(X.shape[1]):\n",
    "    tmp = pd.DataFrame({\n",
    "        'x': df.Acquisition.values,\n",
    "        'y': X[:,i]\n",
    "    })\n",
    "    OLS_model = ols_f(\"y ~ C(x)\", tmp).fit()  # training the model\n",
    "    X_adj[:, i] = OLS_model.resid.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T13:11:32.538414Z",
     "start_time": "2021-08-01T13:08:49.530346Z"
    }
   },
   "outputs": [],
   "source": [
    "# nested cv\n",
    "outer_cv = KFold(10)\n",
    "inner_cv = KFold(10)                                    \n",
    "clf = GridSearchCV(estimator=model, param_grid=p_grid, cv=inner_cv,\n",
    "                   scoring=\"neg_mean_squared_error\", verbose=True, return_train_score=False,\n",
    "                   n_jobs=-1)\n",
    "\n",
    "all_models = []\n",
    "best_params = []\n",
    "predicted = np.zeros(len(y))\n",
    "nested_scores_train = np.zeros(outer_cv.get_n_splits(X_adj))\n",
    "nested_scores_test = np.zeros(outer_cv.get_n_splits(X_adj))   \n",
    "                                    \n",
    "print(\"model\\tinner_cv mean score\\touter vc score\")\n",
    "i=0\n",
    "for train, test in outer_cv.split(X_adj, y):\n",
    "\n",
    "    \n",
    "    \n",
    "    clf.fit(X_adj[train], y[train])\n",
    "    \n",
    "                                    \n",
    "    print('cv:', i, str(clf.best_params_) + \" \" + str(clf.best_score_) + \" \" + str(clf.score(X_adj[test], y[test])))\n",
    "                                    \n",
    "    all_models.append(clf.best_estimator_)\n",
    "    best_params.append(clf.best_params_)\n",
    "    \n",
    "    predicted[test] = clf.predict(X_adj[test])\n",
    "                                    \n",
    "    nested_scores_train[i] = clf.best_score_\n",
    "    nested_scores_test[i] = clf.score(X_adj[test], y[test])\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-31T18:04:26.010358Z",
     "start_time": "2021-07-31T18:04:26.006192Z"
    }
   },
   "source": [
    "## Results (acquisition batch regressed out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T13:11:33.810075Z",
     "start_time": "2021-08-01T13:11:32.542866Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"*** Score on mean as model:\\t\" + str(-mean_squared_error(np.repeat(y.mean(), len(y)), y)))\n",
    "print(\"** Mean score in the inner crossvaludation (inner_cv):\\t\" + str(nested_scores_train.mean()))\n",
    "print(\"** Mean Nested Crossvalidation Score (outer_cv):\\t\" + str(nested_scores_test.mean()))\n",
    "print(\"Explained Variance: \" +  str( 1- nested_scores_test.mean()/-mean_squared_error(np.repeat(y.mean(), len(y)), y) ))\n",
    "print(\"Correlation: \" + str(np.corrcoef(y, predicted)[0,1]))\n",
    "        \n",
    "plt.figure(figsize=(5,2))\n",
    "sns.regplot(x=y, y=predicted, scatter=False, color='gray')\n",
    "sns.scatterplot(x=y, y=predicted, hue=df.Acquisition.astype(\"category\").cat.codes.values,\n",
    "                palette=sns.color_palette(\"coolwarm\", as_cmap=True), alpha=0.4)\n",
    "plt.savefig('../data_out/fig/hcp_acq_reg_regplot.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T13:11:45.593189Z",
     "start_time": "2021-08-01T13:11:33.814994Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_graph(test_partially_confounded(y, predicted, pd.Categorical(df['Acquisition'].values).codes, cat_c=True,\n",
    "                                    random_state=42), outfile_base='../data_out/fig/hcp_acq_reg_partial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T13:11:52.132099Z",
     "start_time": "2021-08-01T13:11:45.596246Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_graph(test_fully_confounded(y, predicted, pd.Categorical(df['Acquisition'].values).codes, cat_c=True,\n",
    "                                random_state=42), outfile_base='../data_out/fig/hcp_acq_reg_full')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMBAT age group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T13:18:41.014313Z",
     "start_time": "2021-08-01T13:15:01.621244Z"
    }
   },
   "outputs": [],
   "source": [
    "# nested cv\n",
    "outer_cv = KFold(10)\n",
    "inner_cv = KFold(10)                                    \n",
    "clf = GridSearchCV(estimator=model, param_grid=p_grid, cv=inner_cv,\n",
    "                   scoring=\"neg_mean_squared_error\", verbose=True, return_train_score=False,\n",
    "                   n_jobs=-1)\n",
    "\n",
    "all_models = []\n",
    "best_params = []\n",
    "predicted = np.zeros(len(y))\n",
    "nested_scores_train = np.zeros(outer_cv.get_n_splits(X_adj))\n",
    "nested_scores_test = np.zeros(outer_cv.get_n_splits(X_adj))   \n",
    "                                    \n",
    "print(\"model\\tinner_cv mean score\\touter vc score\")\n",
    "i=0\n",
    "for train, test in outer_cv.split(X, y):\n",
    "\n",
    "    comb = CombatModel()\n",
    "    X_train_combat = comb.fit_transform(X[:,np.sum(X,0)!=0][train],\n",
    "                                   np.array([df.age.astype(\"category\").cat.codes.values[train]]).transpose()\n",
    "                                  )\n",
    "    \n",
    "    clf.fit(X_train_combat, y[train])\n",
    "    \n",
    "    X_test_combat = comb.transform(X[:,np.sum(X,0)!=0][test],\n",
    "                                   np.array([df.age.astype(\"category\").cat.codes.values[test]]).transpose()\n",
    "                                  )\n",
    "                                    \n",
    "    print('cv:', i, str(clf.best_params_) + \" \" + str(clf.best_score_) + \" \" + str(clf.score(X_test_combat, y[test])))\n",
    "                                    \n",
    "    all_models.append(clf.best_estimator_)\n",
    "    best_params.append(clf.best_params_)\n",
    "    \n",
    "    predicted[test] = clf.predict(X_test_combat)\n",
    "                                    \n",
    "    nested_scores_train[i] = clf.best_score_\n",
    "    nested_scores_test[i] = clf.score(X_test_combat, y[test])\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results (combat age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T13:18:42.374248Z",
     "start_time": "2021-08-01T13:18:41.024365Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"*** Score on mean as model:\\t\" + str(-mean_squared_error(np.repeat(y.mean(), len(y)), y)))\n",
    "print(\"** Mean score in the inner crossvaludation (inner_cv):\\t\" + str(nested_scores_train.mean()))\n",
    "print(\"** Mean Nested Crossvalidation Score (outer_cv):\\t\" + str(nested_scores_test.mean()))\n",
    "print(\"Explained Variance: \" +  str( 1- nested_scores_test.mean()/-mean_squared_error(np.repeat(y.mean(), len(y)), y) ))\n",
    "print(\"Correlation: \" + str(np.corrcoef(y, predicted)[0,1]))\n",
    "  \n",
    "plt.figure(figsize=(5,2))\n",
    "sns.regplot(x=y, y=predicted, scatter=False, color='gray')\n",
    "sns.scatterplot(x=y, y=predicted, hue=df.age,\n",
    "                palette=sns.color_palette(\"coolwarm\", as_cmap=True), alpha=0.4)\n",
    "plt.savefig('../data_out/fig/hcp_age_comb_regplot.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T12:59:47.086784Z",
     "start_time": "2021-08-01T12:59:38.246036Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_graph(test_partially_confounded(y, predicted, df['age'], random_state=42),\n",
    "          outfile_base='../data_out/fig/hcp_age_comb_partial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T12:59:55.313294Z",
     "start_time": "2021-08-01T12:59:47.089751Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_graph(test_fully_confounded(y, predicted, df['age'], random_state=42),\n",
    "          outfile_base='../data_out/fig/hcp_age_comb_full')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-31T18:05:52.266109Z",
     "start_time": "2021-07-31T18:05:52.263144Z"
    }
   },
   "source": [
    "# COMBAT acquisition batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T13:03:27.864620Z",
     "start_time": "2021-08-01T12:59:55.316441Z"
    }
   },
   "outputs": [],
   "source": [
    "# nested cv\n",
    "outer_cv = KFold(10)\n",
    "inner_cv = KFold(10)                                    \n",
    "clf = GridSearchCV(estimator=model, param_grid=p_grid, cv=inner_cv,\n",
    "                   scoring=\"neg_mean_squared_error\", verbose=True, return_train_score=False,\n",
    "                   n_jobs=-1)\n",
    "\n",
    "all_models = []\n",
    "best_params = []\n",
    "predicted = np.zeros(len(y))\n",
    "nested_scores_train = np.zeros(outer_cv.get_n_splits(X_adj))\n",
    "nested_scores_test = np.zeros(outer_cv.get_n_splits(X_adj))   \n",
    "                                    \n",
    "print(\"model\\tinner_cv mean score\\touter vc score\")\n",
    "i=0\n",
    "for train, test in outer_cv.split(X, y):\n",
    "\n",
    "    comb = CombatModel()\n",
    "    X_train_combat = comb.fit_transform(X[:,np.sum(X,0)!=0][train],\n",
    "                                   np.array([df.Acquisition.astype(\"category\").cat.codes.values[train]]).transpose()\n",
    "                                  )\n",
    "    \n",
    "    clf.fit(X_train_combat, y[train])\n",
    "    \n",
    "    X_test_combat = comb.transform(X[:,np.sum(X,0)!=0][test],\n",
    "                                   np.array([df.Acquisition.astype(\"category\").cat.codes.values[test]]).transpose()\n",
    "                                  )\n",
    "                                    \n",
    "    print('cv:', i, str(clf.best_params_) + \" \" + str(clf.best_score_) + \" \" + str(clf.score(X_test_combat, y[test])))\n",
    "                                    \n",
    "    all_models.append(clf.best_estimator_)\n",
    "    best_params.append(clf.best_params_)\n",
    "    \n",
    "    predicted[test] = clf.predict(X_test_combat)\n",
    "                                    \n",
    "    nested_scores_train[i] = clf.best_score_\n",
    "    nested_scores_test[i] = clf.score(X_test_combat, y[test])\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-31T18:06:36.280780Z",
     "start_time": "2021-07-31T18:06:36.273240Z"
    }
   },
   "source": [
    "## Results (combat acquisition batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T15:59:28.172018Z",
     "start_time": "2021-08-01T15:59:26.753669Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"*** Score on mean as model:\\t\" + str(-mean_squared_error(np.repeat(y.mean(), len(y)), y)))\n",
    "print(\"** Mean score in the inner crossvaludation (inner_cv):\\t\" + str(nested_scores_train.mean()))\n",
    "print(\"** Mean Nested Crossvalidation Score (outer_cv):\\t\" + str(nested_scores_test.mean()))\n",
    "print(\"Explained Variance: \" +  str( 1- nested_scores_test.mean()/-mean_squared_error(np.repeat(y.mean(), len(y)), y) ))\n",
    "print(\"Correlation: \" + str(np.corrcoef(y, predicted)[0,1]))\n",
    " \n",
    "plt.figure(figsize=(5,2))\n",
    "\n",
    "sns.regplot(x=y, y=predicted, scatter=False, color='gray')\n",
    "sns.scatterplot(x=y, y=predicted, hue=df.Acquisition.astype(\"category\").cat.codes.values,\n",
    "                palette=sns.color_palette(\"coolwarm\", as_cmap=True), alpha=0.4)\n",
    "plt.savefig('../data_out/fig/hcp_acq_comb_regplot.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T13:03:42.715843Z",
     "start_time": "2021-08-01T13:03:29.615538Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_graph(test_partially_confounded(y, predicted, pd.Categorical(df['Acquisition'].values).codes, cat_c=True,\n",
    "                                    random_state=42), outfile_base='../data_out/fig/hcp_acq_comb_partial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T13:03:49.731309Z",
     "start_time": "2021-08-01T13:03:42.718992Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_graph(test_fully_confounded(y, predicted, pd.Categorical(df['Acquisition'].values).codes, cat_c=True,\n",
    "                                random_state=42), outfile_base='../data_out/fig/hcp_acq_comb_full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T20:05:07.198385Z",
     "start_time": "2021-08-03T20:05:05.538272Z"
    }
   },
   "outputs": [],
   "source": [
    "permutation_test(y, df.age,\n",
    "                 func=lambda x, y: np.corrcoef(x, y)[1][0]**2,\n",
    "                 method='approximate',\n",
    "                 num_rounds=10000,\n",
    "                 seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T21:14:09.399046Z",
     "start_time": "2021-08-03T20:34:16.167679Z"
    }
   },
   "outputs": [],
   "source": [
    "def workhorse(x, y):\n",
    "    df = pd.DataFrame({\n",
    "        'x': x,\n",
    "        'y': y\n",
    "    })\n",
    "    fit = ols_f('y ~ C(x)', data=df).fit()\n",
    "    return fit.rsquared\n",
    "\n",
    "permutation_test(pd.Categorical(df['Acquisition'].values).codes, y,\n",
    "                 func=workhorse,\n",
    "                 method='approximate',\n",
    "                 num_rounds=10000,\n",
    "                 seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.001"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}